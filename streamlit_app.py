# streamlit_app.py - Version compl√®te mise √† jour

import streamlit as st
from src.youtube import extract_video_id
from src.embedding import process_and_store_transcript_txt
from src.qdrant import get_qdrant_client, check_video_exists
from src.retrieve import retrieve_relevant_chunks
from src.query import answer_question_with_grok
from src.embedding import get_embedding_model
from youtube_transcript_api import YouTubeTranscriptApi
from src.loggings import configure_logging
import os
import time

# Configuration du logging
logger = configure_logging(log_file="streamlit_app.log", logger_name="__streamlit_app__")
logger.info("D√©marrage de l'application Streamlit")

# Configuration de la page
st.set_page_config(
    page_title="Naive RAG YouTube",
    page_icon="üé•",
    layout="wide"
)

# === CACHING DES MODELES ===
@st.cache_resource
def load_embedding_model():
    """Charge le mod√®le d'embedding au d√©marrage et le garde en cache"""
    with st.spinner("Chargement du mod√®le d'embedding..."):
        logger.info("Chargement du mod√®le d'embedding...")
        model = get_embedding_model()
        logger.info("Mod√®le d'embedding charg√© avec succ√®s")
        return model

@st.cache_resource
def get_qdrant_client_cached():
    """Cache le client Qdrant"""
    logger.info("Initialisation du client Qdrant...")
    client = get_qdrant_client()
    logger.info("Client Qdrant initialis√©")
    return client

# === CONSTANTES ===
COLLECTION_NAME = "youtube_transcripts"
AVAILABLE_MODELS = [
    "openai/gpt-oss-120b",
    "openai/gpt-oss-20b", 
    "qwen/qwen3-32b"
]
DEFAULT_MODEL = "openai/gpt-oss-120b"
DEFAULT_TEMPERATURE = 0.7
DEFAULT_MAX_TOKENS = 1000
DEFAULT_LANGUAGE = "en"

# === INITIALISATION ===
if 'messages' not in st.session_state:
    st.session_state.messages = []
    logger.debug("Initialisation de st.session_state.messages")
if 'current_video_id' not in st.session_state:
    st.session_state.current_video_id = None
    logger.debug("Initialisation de st.session_state.current_video_id")
if 'video_processed' not in st.session_state:
    st.session_state.video_processed = False
    logger.debug("Initialisation de st.session_state.video_processed")
if 'temperature' not in st.session_state:
    st.session_state.temperature = DEFAULT_TEMPERATURE
    logger.debug("Initialisation de st.session_state.temperature")
if 'max_tokens' not in st.session_state:
    st.session_state.max_tokens = DEFAULT_MAX_TOKENS
    logger.debug("Initialisation de st.session_state.max_tokens")
if 'selected_language' not in st.session_state:
    st.session_state.selected_language = DEFAULT_LANGUAGE
    logger.debug("Initialisation de st.session_state.selected_language")
if 'available_languages' not in st.session_state:
    st.session_state.available_languages = []
    logger.debug("Initialisation de st.session_state.available_languages")

# Charger les mod√®les au d√©marrage
try:
    embedding_model = load_embedding_model()
    qdrant_client = get_qdrant_client_cached()
    ytt = YouTubeTranscriptApi()
    logger.info("Tous les mod√®les et clients charg√©s avec succ√®s")
except Exception as e:
    logger.error(f"Erreur lors du chargement des mod√®les/clients: {e}")
    st.error("Erreur lors du chargement de l'application. Veuillez consulter les logs.")

# === SIDEBAR ===
with st.sidebar:
    st.title("üé• Naive RAG YouTube")
    st.markdown("---")
    
    # Input URL
    youtube_url = st.text_input("üîó URL YouTube", placeholder="https://www.youtube.com/watch?v=...")

    # Ajouter un s√©lecteur de langue pour la r√©ponse (pas pour l'ingestion)
    response_language = st.selectbox(
        "üåç Langue de r√©ponse",
        options=["Fran√ßais", "English", "Espa√±ol", "Deutsch"],
        index=0
    )

    # Convertir en code langue
    language_codes = {"Fran√ßais": "fr", "English": "en", "Espa√±ol": "es", "Deutsch": "de"}
    selected_response_language = language_codes[response_language]

    # S√©lecteur de mod√®le
    selected_model = st.selectbox(
        "ü§ñ Mod√®le de r√©ponse",
        options=AVAILABLE_MODELS,
        index=AVAILABLE_MODELS.index(DEFAULT_MODEL) if DEFAULT_MODEL in AVAILABLE_MODELS else 0
    )
 

    
    st.markdown("---")
    
    # Param√®tres de g√©n√©ration
    st.subheader("‚öôÔ∏è Param√®tres de g√©n√©ration")
    st.session_state.temperature = st.slider(
        "Temp√©rature", 
        min_value=0.0, 
        max_value=1.0, 
        value=float(st.session_state.temperature), 
        step=0.1,
        help="Contr√¥le la cr√©ativit√© de la r√©ponse (0 = d√©terministe, 1 = cr√©atif)"
    )
    
    st.session_state.max_tokens = st.slider(
        "Max Tokens", 
        min_value=100, 
        max_value=2000, 
        value=int(st.session_state.max_tokens), 
        step=100,
        help="Longueur maximale de la r√©ponse"
    )
    
    st.markdown("---")
    
    # Dans streamlit_app.py - Remplacer la section de d√©tection des langues par :

    if youtube_url:
        logger.info(f"Traitement de l'URL YouTube: {youtube_url}")
        
        # Extraire l'ID de la vid√©o
        video_id = extract_video_id(youtube_url)
        
        if not video_id:
            st.error("‚ùå URL YouTube invalide")
            logger.warning(f"URL YouTube invalide fournie: {youtube_url}")
        else:
            # V√©rifier si la vid√©o existe d√©j√† (dans la langue par d√©faut ou la langue s√©lectionn√©e)
            logger.info(f"V√©rification de l'existence de la vid√©o {video_id} dans Qdrant...")
            video_exists = check_video_exists(qdrant_client, COLLECTION_NAME, video_id)
            
            if video_exists:
                st.success(f"‚úÖ Vid√©o d√©j√† trait√©e (ID: {video_id})")
                logger.info(f"Vid√©o {video_id} d√©j√† pr√©sente dans la base")
                st.session_state.current_video_id = video_id
                st.session_state.video_processed = True
            else:
                st.warning("üîÑ Vid√©o non trait√©e - Lancement de l'ingestion...")
                logger.info(f"Vid√©o {video_id} non trouv√©e, d√©marrage de l'ingestion...")
                
                # Processus d'ingestion - garder l'approche originale
                try:
                    with st.spinner("üì• R√©cup√©ration de la transcription..."):
                        logger.info(f"R√©cup√©ration de la transcription pour {video_id}")
                        # Utiliser l'approche originale
                        transcript = ytt.fetch(video_id=video_id, languages=['en', 'fr'])  # ou juste ['en']
                        logger.info(f"Transcription r√©cup√©r√©e ({len(transcript)} segments)")
                    
                    with st.spinner("üíæ Sauvegarde de la transcription..."):
                        logger.info(f"Sauvegarde de la transcription pour {video_id}")
                        os.makedirs("./downloads", exist_ok=True)
                        txt_file_name = f"{video_id}.txt"
                        txt_file_path = f"./downloads/{txt_file_name}"
                        
                        try:
                            from src.youtube import save_txt
                            save_txt(transcript, out_path=txt_file_name)
                            logger.info(f"Transcription sauvegard√©e dans {txt_file_path}")
                        except Exception as e:
                            logger.error(f"Erreur lors de la sauvegarde de la transcription pour {video_id}: {e}")
                            raise
                    
                    with st.spinner("üß† Traitement et stockage dans Qdrant..."):
                        logger.info(f"Traitement et stockage de {video_id} dans Qdrant")
                        # Utiliser la version originale sans language_code
                        from src.embedding import process_and_store_transcript_txt
                        process_and_store_transcript_txt(
                            txt_file_path=txt_file_path,
                            collection_name=COLLECTION_NAME,
                            video_id=video_id,
                            chunk_size=700,
                            chunk_overlap=100
                        )
                        
                    with st.spinner("üîç V√©rification du stockage..."):
                        video_stored = check_video_exists(qdrant_client, COLLECTION_NAME, video_id)
                        if video_stored:
                            logger.info(f"Vid√©o {video_id} confirm√©e dans Qdrant")
                            st.success("‚úÖ Vid√©o trait√©e et stock√©e avec succ√®s!")
                            st.session_state.current_video_id = video_id
                            st.session_state.video_processed = True
                        else:
                            logger.warning(f"Vid√©o {video_id} non trouv√©e dans Qdrant apr√®s ingestion")
                            st.warning("‚ö†Ô∏è Probl√®me lors du stockage - aucun chunk trouv√©")
                            st.session_state.video_processed = False
                    
                except Exception as e:
                    error_msg = f"‚ùå Erreur lors du traitement: {str(e)}"
                    st.error(error_msg)
                    logger.error(f"Erreur lors du traitement de la vid√©o {video_id}: {e}")
                    st.session_state.video_processed = False
# === CHAT INTERFACE ===
st.title("üí¨ Chat avec votre vid√©o YouTube")

# Afficher l'historique des messages
logger.debug(f"Affichage de {len(st.session_state.messages)} messages dans l'historique")
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input utilisateur
if prompt := st.chat_input("Posez votre question sur la vid√©o...", 
                          disabled=not st.session_state.video_processed):
    
    logger.info(f"Question utilisateur: {prompt}")
    # Ajouter le message utilisateur
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # R√©ponse de l'assistant
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            if not st.session_state.current_video_id:
                full_response = "‚ùå Aucune vid√©o s√©lectionn√©e. Veuillez entrer une URL YouTube dans la sidebar."
                logger.warning("Tentative de question sans vid√©o s√©lectionn√©e")
            else:
                # R√©cup√©rer les chunks pertinents avec la langue s√©lectionn√©e
                with st.spinner("üîç Recherche des informations pertinentes..."):
                    logger.info(f"Recherche de chunks pertinents pour: {prompt}")
                    retrieved_chunks = retrieve_relevant_chunks(
                        query=prompt,
                        collection_name=COLLECTION_NAME,
                        video_id=st.session_state.current_video_id,
                        top_k=10
                    )
                    logger.info(f"Trouv√© {len(retrieved_chunks)} chunks pertinents")
                
                if not retrieved_chunks:
                    full_response = "‚ùå Je n'ai trouv√© aucune information pertinente dans la vid√©o pour r√©pondre √† votre question."
                    logger.info("Aucun chunk pertinent trouv√© pour la requ√™te")
                else:
                    with st.spinner("ü§ñ G√©n√©ration de la r√©ponse..."):
                        logger.info(f"G√©n√©ration de r√©ponse avec le mod√®le {selected_model}")
                        # Vous pouvez ajouter une instruction dans le prompt pour la langue de r√©ponse
                        prompt_with_language = f"R√©ponds en {response_language}: {prompt}"
                        
                        full_response = answer_question_with_grok(
                            question=prompt_with_language,
                            chunks=retrieved_chunks,
                            model=selected_model,
                            max_tokens=st.session_state.max_tokens,
                            temperature=st.session_state.temperature,
                            conversation_history=st.session_state.messages
                        )
            
            # Afficher la r√©ponse progressivement (effet de frappe)
            for chunk in full_response.split():
                full_response += chunk + " "
                time.sleep(0.05)
                message_placeholder.markdown(full_response + "‚ñå")
            message_placeholder.markdown(full_response)
            
        except Exception as e:
            error_response = f"‚ùå Une erreur s'est produite: {str(e)}"
            message_placeholder.markdown(error_response)
            logger.error(f"Erreur lors de la g√©n√©ration de la r√©ponse: {e}")
            full_response = error_response
    
    # Ajouter la r√©ponse √† l'historique
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    logger.debug("R√©ponse ajout√©e √† l'historique")

# Bouton pour r√©initialiser la conversation
if st.sidebar.button("üóëÔ∏è R√©initialiser la conversation"):
    logger.info("R√©initialisation de la conversation demand√©e")
    st.session_state.messages = []
    st.session_state.current_video_id = None
    st.session_state.video_processed = False
    st.session_state.selected_language = DEFAULT_LANGUAGE
    st.session_state.available_languages = []
    st.rerun()

logger.info("Fin du rendu de l'application Streamlit")